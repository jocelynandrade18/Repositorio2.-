{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUfbQfQ8La16dLQ1jhrTaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jocelynandrade18/Repositorio2.-/blob/main/NOT_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELO **PERCEPTRÓN**\n",
        "\n"
      ],
      "metadata": {
        "id": "C5NFOgEserSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos el modelo del perceptron para resolver el problema de la Operacion logica ´NOT´"
      ],
      "metadata": {
        "id": "6P4Cz6IJer7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    # Función que se ejecuta al crear el Perceptrón\n",
        "    def __init__(self, peso_inicial, sesgo_inicial, tasa_de_aprendizaje):\n",
        "      # Guardamos los valores iniciales. El NOT solo necesita 1 peso.\n",
        "      self.peso = peso_inicial\n",
        "      self.sesgo = sesgo_inicial\n",
        "      self.tasa = tasa_de_aprendizaje\n",
        "\n",
        "    # Función que decide la salida (Función de Activación)\n",
        "    def activar(self, z):\n",
        "      \"\"\"Si z es 0 o positivo, la salida es 1. Si es negativo, es 0.\"\"\"\n",
        "      if z >= 0:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "\n",
        "    # Función para enseñar al Perceptrón a resolver NOT\n",
        "    def entrenar(self, Entradas_X, Salidas_Y, epocas):\n",
        "      print(\"INICIO DEL ENTRENAMIENTO\")\n",
        "\n",
        "      # Repetimos el proceso de ajuste en varias épocas\n",
        "      for epoca in range(epocas):\n",
        "        error_total = 0\n",
        "\n",
        "        # Recorremos cada ejemplo de entrenamiento\n",
        "        # 'i' es el índice, 'x' es la entrada (0 o 1)\n",
        "        for i, x in enumerate(Entradas_X):\n",
        "          x1 = x[0] # Tomamos el único valor de entrada (0 o 1)\n",
        "          y_real = Salidas_Y[i]\n",
        "\n",
        "          # Multiplicamos la entrada por el peso y sumamos el sesgo\n",
        "          z = (x1 * self.peso) + self.sesgo\n",
        "\n",
        "          # El Perceptrón hace su predicción (y_pred)\n",
        "          y_pred = self.activar(z)\n",
        "\n",
        "          # Error: Qué tan lejos estamos del resultado correcto\n",
        "          error = y_real - y_pred\n",
        "          error_total += abs(error) # Contamos el error para saber si terminamos\n",
        "\n",
        "          # Si hay error, cambiamos el peso y el sesgo\n",
        "          if error != 0:\n",
        "              # Regla de ajuste: Tasa * Error * Entrada\n",
        "              ajuste_peso = self.tasa * error * x1\n",
        "              self.peso += ajuste_peso\n",
        "\n",
        "              # El sesgo siempre se ajusta\n",
        "              ajuste_sesgo = self.tasa * error\n",
        "              self.sesgo += ajuste_sesgo\n",
        "\n",
        "          print(f\"  Entrada: [{x1}], Real: {y_real}, Prediccion: {y_pred}, Error: {error}, Nuevo Peso: {self.peso:.4f}, Nuevo Sesgo: {self.sesgo:.4f}\")\n",
        "\n",
        "        print(f\"\\nEpoca {epoca+1} completada. Error Total Absoluto: {error_total}\")\n",
        "\n",
        "        # Si el error total es 0, la neurona ya está lista, y nos detenemos\n",
        "        if error_total == 0:\n",
        "            print(\"La neurona está lista.\")\n",
        "            break\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    def predecir(self, Entradas_X, Salidas_Y):\n",
        "      print(\"\\n PREDICCIÓN FINAL NOT\")\n",
        "      for i, x in enumerate(Entradas_X):\n",
        "        x1 = x[0]\n",
        "        y_real = Salidas_Y[i]\n",
        "\n",
        "        # Recalculamos la suma ponderada con los pesos finales\n",
        "        z = (x1 * self.peso) + self.sesgo\n",
        "        y_pred = self.activar(z)\n",
        "\n",
        "        print(f\"Entrada [{x1}] -> Predicción: {y_pred}, Valor Real: {y_real}\")\n",
        "\n",
        "print(\"ENTRENAMIENTO PARA LA OPERACIÓN LÓGICA NOT\")\n",
        "# Datos de entrenamiento\n",
        "# NOT 0 = 1, NOT 1 = 0\n",
        "X_NOT = [[0], [1]] # Las entradas\n",
        "Y_NOT = [1, 0]     # Los resultados esperados\n",
        "\n",
        "# Parámetros iniciales\n",
        "peso_inicial = 0.0      # El peso comienza en cero\n",
        "sesgo_inicial = 0.0     # El sesgo comienza en cero\n",
        "tasa_de_aprendizaje = 0.1 # Qué tan grande debe ser cada ajuste\n",
        "\n",
        "# Creamos la neurona (Perceptrón)\n",
        "perceptron = Perceptron(peso_inicial, sesgo_inicial, tasa_de_aprendizaje)\n",
        "\n",
        "# Entrenamos la neurona\n",
        "epocas = 10\n",
        "perceptron.entrenar(X_NOT, Y_NOT, epocas)\n",
        "\n",
        "# Probamos el resultado final\n",
        "perceptron.predecir(X_NOT, Y_NOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdQqzXNIH7ta",
        "outputId": "17f7d883-ebe1-4426-f255-814031742b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTRENAMIENTO PARA LA OPERACIÓN LÓGICA NOT\n",
            "INICIO DEL ENTRENAMIENTO\n",
            "  Entrada: [0], Real: 1, Prediccion: 1, Error: 0, Nuevo Peso: 0.0000, Nuevo Sesgo: 0.0000\n",
            "  Entrada: [1], Real: 0, Prediccion: 1, Error: -1, Nuevo Peso: -0.1000, Nuevo Sesgo: -0.1000\n",
            "\n",
            "Epoca 1 completada. Error Total Absoluto: 1\n",
            "----------------------------------------------------------------------\n",
            "  Entrada: [0], Real: 1, Prediccion: 0, Error: 1, Nuevo Peso: -0.1000, Nuevo Sesgo: 0.0000\n",
            "  Entrada: [1], Real: 0, Prediccion: 0, Error: 0, Nuevo Peso: -0.1000, Nuevo Sesgo: 0.0000\n",
            "\n",
            "Epoca 2 completada. Error Total Absoluto: 1\n",
            "----------------------------------------------------------------------\n",
            "  Entrada: [0], Real: 1, Prediccion: 1, Error: 0, Nuevo Peso: -0.1000, Nuevo Sesgo: 0.0000\n",
            "  Entrada: [1], Real: 0, Prediccion: 0, Error: 0, Nuevo Peso: -0.1000, Nuevo Sesgo: 0.0000\n",
            "\n",
            "Epoca 3 completada. Error Total Absoluto: 0\n",
            "La neurona está lista.\n",
            "\n",
            " PREDICCIÓN FINAL NOT\n",
            "Entrada [0] -> Predicción: 1, Valor Real: 1\n",
            "Entrada [1] -> Predicción: 0, Valor Real: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación de lo que hace la Neurona con la opreación lógica NOT"
      ],
      "metadata": {
        "id": "53L0_mf2S47d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La operación NOT solo tiene dos reglas:\n",
        "Si le das un **0**, debe decir **1**.\n",
        "Si le das un **1**, debe decir **0**.\n",
        "\n",
        "El código inicia un **entrenamiento** que se repite por **10 épocas**\n",
        "\n",
        "La neurona toma una entrada (el 0), Lo multiplica por el peso actual y le suma el sesgo. El resultado de la suma, si es cero o positivo, la neurona \"predice\" 1; si es negativo, predice 0.\n",
        "\n",
        "Compara su predicción (si la entrada fue 0, debía ser 1). Si acierta, no hace nada. Si se equivoca, eso es un error.\n",
        "\n",
        "Si hay un error, la neurona sabe que el peso y sesgo están mal y las ajusta cpn la tasa de aprendizaje para dar el resultado correcto.\n",
        "\n",
        "Este proceso se repite una y otra vez con la entrada 0 y luego con la entrada 1.\n",
        "\n",
        "Cuando le das un 0, la suma da un número positivo, así que predice 1.\n",
        "Cuando le das un 1, la suma da un número negativo, así que predice 0.\n",
        "\n",
        "Cuando la neurona logra esto, el error total es cero, el código se detiene y la neurona ha realizado la operación NOT e imprime solo hasta la época en la que se haya cumplido esta condición."
      ],
      "metadata": {
        "id": "hDiIvpD-TE8t"
      }
    }
  ]
}
